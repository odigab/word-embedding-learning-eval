%
% File acl2013.tex
%
% Contact  navigli@di.uniroma1.it
%%
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2013}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{color}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{subfig}
\usepackage{pgfplotstable}
\usepackage{adjustbox}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsmath}


\title{Evaluation of Word Embeddings for Sequence Tagging Tasks}

\author{A Anonymous 
   \\%NICTA / Locked Bag 8001, \\ Canberra ACT 2601, Australia \\
   \\ %The Australian National University\\
   \\ %University of Canberra \\
  \\ % {\tt \small{@nicta.com.au}} \\
\And
  B Anonymous
   \\%NICTA / Locked Bag 8001, \\ Canberra ACT 2601, Australia \\
   \\%The Australian National University\\ \\
   \\ %{\tt \small{@nicta.com.au}} \\
}

\date{2014}

% Max 8 pp.

\begin{document}


\maketitle


\begin{abstract} 
  Word embeddings are distributed word representations which can be
  learned from unlabelled data, and have been shown to have high utility
  in many NLP applications. 
  In this paper, we perform an extrinsic evaluation of five popular word
  embedding methods in the context of four sequence labelling tasks:
  POS-tagging, chunking, NER and MWE identification.
  A particular focus of the paper is analysis of the impact of fine-tuning the word
  representations during training.
  We show that when using word embeddings as features, as few as
  several hundred training instances are sufficient to achieve competitive
  results, and that word embeddings lead to improvements in results over
  all tasks.
  % We also find, however, that fine-tuning can result in over-fitting, in the situation 
  % where the pre-trained representations were already good.
  Perhaps more surprisingly, our results indicate that there is very
  little difference between the different word embedding methods, and
  indeed, that simple Brown clusters are often competitive with word
  embeddings across all tasks we consider. 
\end{abstract}

\newcommand{\gabi}[1]{\textcolor{blue}{#1}}
\newcommand{\tim}[1]{\textcolor{red}{#1}}
\newcommand{\lizhen}[1]{\textcolor{green}{#1}}
\newcommand{\nss}[1]{\textcolor{magenta}{#1}}

\input{intro}
\input{wordRep}
\input{seqTagging}
\input{results}
\input{relwork}
\input{conclusion}

\section*{Acknowledgments}

Anonymised\\
Anonymised\\
Anonymised\\
Anonymised\\
Anonymised\\
Anonymised\\

%NICTA is funded by the Australian Government as represented by the Department of Broadband, Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program.

\bibliographystyle{acl2013}
\bibliography{biblio}

\end{document}

