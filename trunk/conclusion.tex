\section{Conclusion}
We have performed an extensive extrinsic evaluation of five word embeddings methods approaches
under fixed experiments conditions, and evaluate them over different sequence tagging tasks: POS-tagging, chunking, NER and MWE identification.
We found that word embeddings methods always outperformed unigram features, especially when the training size is small, but no method was consistently better than the others across the different tasks and settings.
Word representations were also found useful for improving the accuracy of OOV.
We expected to see an important gap between the performance of fine-tuned features in a semi-supervised setting and no fine-tuned ones, but the difference is marginal.
Nevertheless, we found that fine-tuning can result in over-fitting, when the ones learned  unsupervised were already good.   
Finally, by using word embeddings as features for MWE identification, we outperformed 
the state-of-the-art system.
%We could not find any trend that suggest that a word embedding method is better than other.
Future studies include learning representation of complex sequences such as MWEs.


